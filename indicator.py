import akshare as ak
import pandas as pd
from datetime import datetime
import json
import requests
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IndicatorBot:
    def __init__(self, config_file='config.json'):
        """åˆå§‹åŒ–é…ç½®"""
        with open(config_file, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.dingtalk_config = self.config['cn_config']['dingtalk']
    
    def get_stock_indicators(self):
        """è·å–è‚¡ç¥¨ç›¸å…³æŒ‡æ ‡æ•°æ®"""
        logger.info(f"å¼€å§‹è·å–è‚¡ç¥¨æŒ‡æ ‡æ•°æ® - {datetime.now()}")
        
        indicators_data = {}
        
        # 1. è‚¡å€ºåˆ©å·® - åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
        logger.info("æ­£åœ¨è·å–è‚¡å€ºåˆ©å·®æ•°æ®...")
        try:
            stock_ebs_lg_df = ak.stock_ebs_lg()
            if not stock_ebs_lg_df.empty:
                # å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
                latest_ebs = stock_ebs_lg_df.iloc[-1]
                indicators_data['è‚¡å€ºåˆ©å·®'] = latest_ebs.to_dict()
                logger.info("è‚¡å€ºåˆ©å·®æ•°æ®è·å–æˆåŠŸ")
            else:
                logger.warning("è‚¡å€ºåˆ©å·®æ•°æ®ä¸ºç©º")
                indicators_data['è‚¡å€ºåˆ©å·®'] = "æ•°æ®ä¸ºç©º"
        except Exception as e:
            logger.error(f"è·å–è‚¡å€ºåˆ©å·®æ•°æ®å¤±è´¥: {e}")
            indicators_data['è‚¡å€ºåˆ©å·®'] = f"è·å–å¤±è´¥: {e}"
        
        # 2. å·´è²ç‰¹æŒ‡æ ‡ - åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
        logger.info("æ­£åœ¨è·å–å·´è²ç‰¹æŒ‡æ ‡æ•°æ®...")
        try:
            stock_buffett_index_lg_df = ak.stock_buffett_index_lg()
            if not stock_buffett_index_lg_df.empty:
                # å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
                latest_buffett = stock_buffett_index_lg_df.iloc[-1]
                indicators_data['å·´è²ç‰¹æŒ‡æ ‡'] = latest_buffett.to_dict()
                logger.info("å·´è²ç‰¹æŒ‡æ ‡æ•°æ®è·å–æˆåŠŸ")
            else:
                logger.warning("å·´è²ç‰¹æŒ‡æ ‡æ•°æ®ä¸ºç©º")
                indicators_data['å·´è²ç‰¹æŒ‡æ ‡'] = "æ•°æ®ä¸ºç©º"
        except Exception as e:
            logger.error(f"è·å–å·´è²ç‰¹æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            indicators_data['å·´è²ç‰¹æŒ‡æ ‡'] = f"è·å–å¤±è´¥: {e}"
        
        # 3. Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡ - æ–°å¢å­—æ®µå¹¶é‡å‘½å
        logger.info("æ­£åœ¨è·å–Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®...")
        try:
            stock_a_ttm_lyr_df = ak.stock_a_ttm_lyr()
            if not stock_a_ttm_lyr_df.empty:
                # å®šä¹‰å­—æ®µæ˜ å°„å…³ç³»
                field_mapping = {
                    'date': 'æ—¥æœŸ',
                    'middlePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ä¸­ä½æ•°',
                    'averagePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ç­‰æƒå¹³å‡',
                    'quantileInRecent10YearsMiddlePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ä¸­ä½æ•°"åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°',
                    'quantileInRecent10YearsAveragePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ç­‰æƒå¹³å‡"åœ¨åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°'
                }
                
                # æ£€æŸ¥å“ªäº›å­—æ®µå­˜åœ¨
                available_columns = [col for col in field_mapping.keys() if col in stock_a_ttm_lyr_df.columns]
                
                if available_columns:
                    latest_pe_data = stock_a_ttm_lyr_df[available_columns].iloc[-1]
                    # é‡å‘½åå­—æ®µ
                    renamed_data = {}
                    for col in available_columns:
                        renamed_data[field_mapping[col]] = latest_pe_data[col]
                    indicators_data['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = renamed_data
                    logger.info("Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡æ•°æ®è·å–æˆåŠŸ")
                else:
                    logger.warning("æœªæ‰¾åˆ°æŒ‡å®šçš„å­—æ®µ")
                    indicators_data['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = "æŒ‡å®šå­—æ®µä¸å­˜åœ¨"
            else:
                logger.warning("Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®ä¸ºç©º")
                indicators_data['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = "æ•°æ®ä¸ºç©º"
        except Exception as e:
            logger.error(f"è·å–Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®å¤±è´¥: {e}")
            indicators_data['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = f"è·å–å¤±è´¥: {e}"
        
        logger.info(f"æ•°æ®è·å–å®Œæˆ - {datetime.now()}")
        return indicators_data
    
    def format_message(self, indicators_data):
        """æ ¼å¼åŒ–é’‰é’‰æ¶ˆæ¯"""
        logger.info("å¼€å§‹æ ¼å¼åŒ–æ¶ˆæ¯")
        
        current_date = datetime.now().strftime('%Y-%m-%d')
        
        message_lines = [
            "ğŸ“Š **è‚¡ç¥¨æŒ‡æ ‡æ•°æ®æ’­æŠ¥**",
            f"ğŸ“… **æ—¥æœŸ**: {current_date}",
            ""
        ]
        
        try:
            # è‚¡å€ºåˆ©å·®
            if 'è‚¡å€ºåˆ©å·®' in indicators_data:
                message_lines.append("ğŸ“ˆ **è‚¡å€ºåˆ©å·®**")
                ebs_data = indicators_data['è‚¡å€ºåˆ©å·®']
                if isinstance(ebs_data, dict):
                    for key, value in ebs_data.items():
                        if key == 'date':
                            message_lines.append(f"ğŸ“… æ—¥æœŸ: {value}")
                        else:
                            message_lines.append(f"ğŸ“Š {key}: {value}")
                else:
                    message_lines.append(f"âŒ {ebs_data}")
                message_lines.append("")
            
            # å·´è²ç‰¹æŒ‡æ ‡
            if 'å·´è²ç‰¹æŒ‡æ ‡' in indicators_data:
                message_lines.append("ğŸ’° **å·´è²ç‰¹æŒ‡æ ‡**")
                buffett_data = indicators_data['å·´è²ç‰¹æŒ‡æ ‡']
                if isinstance(buffett_data, dict):
                    for key, value in buffett_data.items():
                        if key == 'date':
                            message_lines.append(f"ğŸ“… æ—¥æœŸ: {value}")
                        else:
                            message_lines.append(f"ğŸ“Š {key}: {value}")
                else:
                    message_lines.append(f"âŒ {buffett_data}")
                message_lines.append("")
            
            # Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡
            if 'Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡' in indicators_data:
                message_lines.append("ğŸ“ˆ **Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡**")
                pe_data = indicators_data['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡']
                if isinstance(pe_data, dict):
                    for key, value in pe_data.items():
                        if 'æ—¥æœŸ' in key:
                            message_lines.append(f"ğŸ“… {key}: {value}")
                        elif 'åˆ†ä½æ•°' in key:
                            # åˆ†ä½æ•°è½¬æ¢ä¸ºç™¾åˆ†æ¯”æ˜¾ç¤º
                            if isinstance(value, (int, float)):
                                percentage = value * 100
                                message_lines.append(f"ğŸ“Š {key}: {percentage:.1f}%")
                            else:
                                message_lines.append(f"ğŸ“Š {key}: {value}")
                        else:
                            message_lines.append(f"ğŸ“Š {key}: {value}")
                else:
                    message_lines.append(f"âŒ {pe_data}")
                message_lines.append("")
            
            message_lines.extend([
                "---",
                "",
                "ğŸ’¡ **æ•°æ®è¯´æ˜**",
                "",
                "ğŸ“Š è‚¡å€ºåˆ©å·®ï¼šè‚¡ç¥¨æ”¶ç›Šç‡ä¸å€ºåˆ¸æ”¶ç›Šç‡çš„å·®å€¼",
                "ğŸ’° å·´è²ç‰¹æŒ‡æ ‡ï¼šè‚¡å¸‚æ€»å¸‚å€¼ä¸GDPçš„æ¯”å€¼",
                "ğŸ“ˆ å¸‚ç›ˆç‡åˆ†ä½æ•°ï¼šå½“å‰ä¼°å€¼åœ¨å†å²æ•°æ®ä¸­çš„ç›¸å¯¹ä½ç½®"
            ])
            
        except Exception as e:
            logger.error(f"æ¶ˆæ¯æ ¼å¼åŒ–é”™è¯¯: {e}", exc_info=True)
            message_lines.append("âŒ æ•°æ®æ ¼å¼åŒ–å¤±è´¥")
        
        # é’‰é’‰éœ€è¦ä½¿ç”¨åŒæ¢è¡Œæ¥ç¡®ä¿åˆ†è¡Œ
        final_message = "\n\n".join(message_lines)
        logger.info("æ¶ˆæ¯æ ¼å¼åŒ–å®Œæˆ")
        return final_message
    
    def send_to_dingtalk(self, message):
        """å‘é€æ¶ˆæ¯åˆ°é’‰é’‰æœºå™¨äºº"""
        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": "è‚¡ç¥¨æŒ‡æ ‡æ•°æ®æ’­æŠ¥",
                "text": message
            }
        }
        
        try:
            logger.info("æ­£åœ¨å‘é€æ¶ˆæ¯åˆ°é’‰é’‰...")
            response = requests.post(
                self.dingtalk_config['webhook_url'],
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logger.info("æ¶ˆæ¯å‘é€æˆåŠŸ")
                    return True
                else:
                    logger.error(f"é’‰é’‰APIè¿”å›é”™è¯¯: {result}")
                    return False
            else:
                logger.error(f"é’‰é’‰è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
                
        except requests.exceptions.RequestException as e:
            logger.error(f"é’‰é’‰è¯·æ±‚å¼‚å¸¸: {e}")
            return False
    
    def run(self):
        """è¿è¡ŒæŒ‡æ ‡æ’­æŠ¥ä»»åŠ¡"""
        success = False
        try:
            logger.info("å¼€å§‹æ‰§è¡Œè‚¡ç¥¨æŒ‡æ ‡æ’­æŠ¥ä»»åŠ¡")
            
            # è·å–æŒ‡æ ‡æ•°æ®
            indicators_data = self.get_stock_indicators()
            
            if indicators_data:
                # æ ¼å¼åŒ–æ¶ˆæ¯
                message = self.format_message(indicators_data)
                
                # å‘é€åˆ°é’‰é’‰
                if self.send_to_dingtalk(message):
                    logger.info("ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
                    success = True
                else:
                    logger.error("é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥")
            else:
                logger.error("è·å–æŒ‡æ ‡æ•°æ®å¤±è´¥")
                
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        
        return success

# ä¿ç•™åŸæœ‰çš„ç‹¬ç«‹å‡½æ•°ï¼Œç”¨äºå‘åå…¼å®¹
def get_stock_indicators():
    """è·å–è‚¡ç¥¨ç›¸å…³æŒ‡æ ‡æ•°æ®ï¼ˆåŸæœ‰å‡½æ•°ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰"""
    print(f"å¼€å§‹è·å–è‚¡ç¥¨æŒ‡æ ‡æ•°æ® - {datetime.now()}")
    
    # 1. è‚¡å€ºåˆ©å·® - åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
    print("æ­£åœ¨è·å–è‚¡å€ºåˆ©å·®æ•°æ®...")
    try:
        stock_ebs_lg_df = ak.stock_ebs_lg()
        if not stock_ebs_lg_df.empty:
            # å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
            latest_ebs = stock_ebs_lg_df.iloc[-1]
            print("è‚¡å€ºåˆ©å·®æœ€æ–°æ•°æ®:")
            print(latest_ebs)
            print("-" * 50)
        else:
            print("è‚¡å€ºåˆ©å·®æ•°æ®ä¸ºç©º")
    except Exception as e:
        print(f"è·å–è‚¡å€ºåˆ©å·®æ•°æ®å¤±è´¥: {e}")
    
    # 2. å·´è²ç‰¹æŒ‡æ ‡ - åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
    print("æ­£åœ¨è·å–å·´è²ç‰¹æŒ‡æ ‡æ•°æ®...")
    try:
        stock_buffett_index_lg_df = ak.stock_buffett_index_lg()
        if not stock_buffett_index_lg_df.empty:
            # å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
            latest_buffett = stock_buffett_index_lg_df.iloc[-1]
            print("å·´è²ç‰¹æŒ‡æ ‡æœ€æ–°æ•°æ®:")
            print(latest_buffett)
            print("-" * 50)
        else:
            print("å·´è²ç‰¹æŒ‡æ ‡æ•°æ®ä¸ºç©º")
    except Exception as e:
        print(f"è·å–å·´è²ç‰¹æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
    
    # 3. Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡ - æ–°å¢å­—æ®µå¹¶é‡å‘½å
    print("æ­£åœ¨è·å–Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®...")
    try:
        stock_a_ttm_lyr_df = ak.stock_a_ttm_lyr()
        if not stock_a_ttm_lyr_df.empty:
            # å®šä¹‰å­—æ®µæ˜ å°„å…³ç³»
            field_mapping = {
                'date': 'æ—¥æœŸ',
                'middlePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ä¸­ä½æ•°',
                'averagePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ç­‰æƒå¹³å‡',
                'quantileInRecent10YearsMiddlePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ä¸­ä½æ•°"åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°',
                'quantileInRecent10YearsAveragePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ç­‰æƒå¹³å‡"åœ¨åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°'
            }
            
            # æ£€æŸ¥å“ªäº›å­—æ®µå­˜åœ¨
            available_columns = [col for col in field_mapping.keys() if col in stock_a_ttm_lyr_df.columns]
            
            if available_columns:
                selected_data = stock_a_ttm_lyr_df[available_columns].copy()
                
                # é‡å‘½åå­—æ®µ
                rename_dict = {col: field_mapping[col] for col in available_columns}
                selected_data = selected_data.rename(columns=rename_dict)
                
                print("Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æŒ‡å®šå­—æ®µæ•°æ®:")
                print(selected_data)
                print(f"\næ•°æ®å½¢çŠ¶: {selected_data.shape}")
                print(f"å¯ç”¨å­—æ®µ: {list(selected_data.columns)}")
                
                # æ˜¾ç¤ºæœ€æ–°æ•°æ®
                if len(selected_data) > 0:
                    print("\næœ€æ–°æ•°æ®:")
                    print(selected_data.iloc[-1])
            else:
                print("æœªæ‰¾åˆ°æŒ‡å®šçš„å­—æ®µ")
                print(f"å¯ç”¨å­—æ®µ: {list(stock_a_ttm_lyr_df.columns)}")
        else:
            print("Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®ä¸ºç©º")
    except Exception as e:
        print(f"è·å–Aè‚¡ç­‰æƒé‡ä¸ä¸­ä½æ•°å¸‚ç›ˆç‡æ•°æ®å¤±è´¥: {e}")
    
    print(f"æ•°æ®è·å–å®Œæˆ - {datetime.now()}")

def get_latest_indicators_summary():
    """è·å–æ‰€æœ‰æŒ‡æ ‡çš„æœ€æ–°æ•°æ®æ‘˜è¦ï¼ˆåŸæœ‰å‡½æ•°ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰"""
    summary = {}
    
    try:
        # è‚¡å€ºåˆ©å·®æœ€æ–°æ•°æ®
        ebs_df = ak.stock_ebs_lg()
        if not ebs_df.empty:
            summary['è‚¡å€ºåˆ©å·®'] = ebs_df.iloc[-1].to_dict()
    except Exception as e:
        summary['è‚¡å€ºåˆ©å·®'] = f"è·å–å¤±è´¥: {e}"
    
    try:
        # å·´è²ç‰¹æŒ‡æ ‡æœ€æ–°æ•°æ®
        buffett_df = ak.stock_buffett_index_lg()
        if not buffett_df.empty:
            summary['å·´è²ç‰¹æŒ‡æ ‡'] = buffett_df.iloc[-1].to_dict()
    except Exception as e:
        summary['å·´è²ç‰¹æŒ‡æ ‡'] = f"è·å–å¤±è´¥: {e}"
    
    try:
        # Aè‚¡å¸‚ç›ˆç‡æŒ‡å®šå­—æ®µæœ€æ–°æ•°æ®
        pe_df = ak.stock_a_ttm_lyr()
        if not pe_df.empty:
            # å®šä¹‰å­—æ®µæ˜ å°„å…³ç³»
            field_mapping = {
                'date': 'æ—¥æœŸ',
                'middlePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ä¸­ä½æ•°',
                'averagePETTM': 'å…¨Aè‚¡æ»šåŠ¨å¸‚ç›ˆç‡(TTM)ç­‰æƒå¹³å‡',
                'quantileInRecent10YearsMiddlePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ä¸­ä½æ•°"åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°',
                'quantileInRecent10YearsAveragePeTtm': 'å½“å‰"TTM(æ»šåŠ¨å¸‚ç›ˆç‡)ç­‰æƒå¹³å‡"åœ¨åœ¨æœ€è¿‘10å¹´æ•°æ®ä¸Šçš„åˆ†ä½æ•°'
            }
            
            available_columns = [col for col in field_mapping.keys() if col in pe_df.columns]
            if available_columns:
                latest_pe_data = pe_df[available_columns].iloc[-1]
                # é‡å‘½åå­—æ®µ
                renamed_data = {}
                for col in available_columns:
                    renamed_data[field_mapping[col]] = latest_pe_data[col]
                summary['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = renamed_data
            else:
                summary['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = "æŒ‡å®šå­—æ®µä¸å­˜åœ¨"
    except Exception as e:
        summary['Aè‚¡å¸‚ç›ˆç‡æŒ‡æ ‡'] = f"è·å–å¤±è´¥: {e}"
    
    return summary

def main():
    """ä¸»å‡½æ•°"""
    try:
        bot = IndicatorBot()
        
        # è¿è¡ŒæŒ‡æ ‡æ’­æŠ¥ä»»åŠ¡
        bot.run()
        
    except FileNotFoundError:
        logger.error("é…ç½®æ–‡ä»¶ config.json ä¸å­˜åœ¨")
    except json.JSONDecodeError:
        logger.error("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©è¿è¡Œæ–¹å¼ï¼š
    # 1. è¿è¡Œé’‰é’‰æ’­æŠ¥ä»»åŠ¡
    main()
    
    # 2. æˆ–è€…è¿è¡ŒåŸæœ‰çš„æ§åˆ¶å°è¾“å‡ºï¼ˆæ³¨é‡Šæ‰ä¸Šé¢çš„main()è°ƒç”¨ï¼‰
    # get_stock_indicators()
    # 
    # print("\n" + "=" * 60)
    # print("æ•°æ®æ‘˜è¦")
    # print("=" * 60)
    # 
    # summary = get_latest_indicators_summary()
    # for key, value in summary.items():
    #     print(f"\n{key}:")
    #     if isinstance(value, dict):
    #         for k, v in value.items():
    #             print(f"  {k}: {v}")
    #     else:
    #         print(f"  {value}")